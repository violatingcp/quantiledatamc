{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98b367f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Sampler, BatchSampler, Dataset, DataLoader, Subset, SubsetRandomSampler, random_split\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "from torch_geometric.nn.conv import DynamicEdgeConv\n",
    "from torch_geometric.nn.pool import avg_pool_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61ce70ab",
   "metadata": {},
   "source": [
    "Ok First lets load the data. We will make an even split between signal and background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65e93ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000, 200, 4])\n",
      "torch.Size([100000, 200, 4])\n",
      "50000 100000\n"
     ]
    }
   ],
   "source": [
    "class DataSet(Dataset):\n",
    "    def __init__(self, samples, labels):\n",
    "        super(DataSet, self).__init__()\n",
    "        self.labels  = labels\n",
    "        self.samples = samples\n",
    "        if len(samples) != len(labels):\n",
    "            raise ValueError(\n",
    "                f\"should have the same number of samples({len(samples)}) as there are labels({len(labels)})\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        y = self.labels[index]\n",
    "        x = self.samples[index]\n",
    "        return x, y\n",
    "\n",
    "def load(filename):\n",
    "    h5file = h5py.File(filename, 'r') # open read-only\n",
    "    mass=h5file.get('jet1_m').astype(\"float32\")\n",
    "    pt=h5file.get('jet1_pt').astype(\"float32\")\n",
    "    t21=h5file.get('jet1_tau21').astype(\"float32\")\n",
    "    t32=h5file.get('jet1_tau32').astype(\"float32\")\n",
    "    total=torch.from_numpy(np.vstack((mass[:],pt[:],t21[:],t32[:])))\n",
    "    total=total.T\n",
    "    return total\n",
    "\n",
    "#note the particles need to be transformed\n",
    "def load_parts(filename):\n",
    "    h5file = h5py.File(filename, 'r') # open read-only\n",
    "    ce=h5file.get('ce').astype(\"float32\")\n",
    "    cpx=h5file.get('cpx').astype(\"float32\")\n",
    "    cpy=h5file.get('cpy').astype(\"float32\")\n",
    "    cpz=h5file.get('cpz').astype(\"float32\")\n",
    "    ce =np.reshape(ce, (len(ce), 1,200))\n",
    "    cpx=np.reshape(cpx,(len(cpx),1,200))\n",
    "    cpy=np.reshape(cpy,(len(cpy),1,200))\n",
    "    cpz=np.reshape(cpz,(len(cpz),1,200))\n",
    "    total=torch.from_numpy(np.hstack((ce,cpx,cpy,cpz)))\n",
    "    total=np.swapaxes(total,1,2)\n",
    "    return total\n",
    "\n",
    "#Basic test (if you want to do this uncomment and comment load_parts)\n",
    "#also comment Dyanmic_Edge bit and uncomment simple_model bit in contr_model\n",
    "#sigtot=load('sig_particleNet_sample.h5')\n",
    "#bkgtot=load('bkg_particleNet_sample.h5')\n",
    "\n",
    "sigtot=load_parts('sig_particleNet_sample.h5')\n",
    "bkgtot=load_parts('bkg_particleNet_sample.h5')\n",
    "siglabel=torch.ones(len(sigtot))\n",
    "bkglabel=torch.zeros(len(bkgtot))\n",
    "print(len(sigtot),len(bkgtot))\n",
    "#data_sig=DataSet(samples=sigtot,labels=siglabel)\n",
    "#data_bkg=DataSet(samples=bkgtot,labels=bkglabel)\n",
    "tot=torch.cat((sigtot,bkgtot[0:50000]))\n",
    "tot=(tot - tot.mean(axis=0))/tot.std(axis=0)\n",
    "label=torch.cat((siglabel,bkglabel[0:50000]))\n",
    "data=DataSet(samples=tot,labels=label)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420972f3",
   "metadata": {},
   "source": [
    "Now we need a sampler that samples both signals and backgrounds in an even way so we can pair them up in augmentation space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ae40121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DelphesSampler(Sampler):\n",
    "    def __init__(self, dataset, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        self.dataset_length = len(dataset)/2\n",
    "        self.n_batches = self.dataset_length / self.batch_size\n",
    "        self.batch_ids = torch.randperm(int(self.n_batches))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        for id in self.batch_ids:\n",
    "            idx1 = torch.arange(id * self.batch_size, (id + 1) * self.batch_size)\n",
    "            idx2 = torch.arange(id * self.batch_size, (id + 1) * self.batch_size)+self.dataset_length\n",
    "            for index in np.append(idx1,idx2):\n",
    "                yield int(index)\n",
    "        if int(self.n_batches) < self.n_batches:\n",
    "            idx1 = torch.arange(int(self.n_batches) * self.batch_size, self.dataset_length)\n",
    "            idx2 = torch.arange(int(self.n_batches) * self.batch_size, self.dataset_length)+self.dataset_length\n",
    "            for index in np.append(idx1,idx2):\n",
    "                yield int(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90049058",
   "metadata": {},
   "source": [
    "Now pick my favorite contrastive loss VICReg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4138873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VICRegLoss(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, lambda_param=1,mu_param=1,nu_param=20,sort_tolerance=1.0,sort_reg='l2'):\n",
    "        super(VICRegLoss, self).__init__()\n",
    "        self.lambda_param = lambda_param\n",
    "        self.mu_param = mu_param\n",
    "        self.nu_param = nu_param\n",
    "        self.tolerance = sort_tolerance\n",
    "        self.reg       = sort_reg\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        repr_loss = F.mse_loss(x, y)\n",
    "        \n",
    "        #x = torch.cat(FullGatherLayer.apply(x), dim=0)\n",
    "        #y = torch.cat(FullGatherLayer.apply(y), dim=0)\n",
    "        x = x - x.mean(dim=0)\n",
    "        y = y - y.mean(dim=0)\n",
    "        N = x.size(0)\n",
    "        D = x.size(1)\n",
    "         \n",
    "        var_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
    "        var_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
    "        std_loss  = torch.mean(F.relu(1 - var_x)) / 2 + torch.mean(F.relu(1 - var_y)) / 2\n",
    "\n",
    "        x = (x-x.mean(dim=0))/x.std(dim=0)\n",
    "        y = (y-y.mean(dim=0))/y.std(dim=0)\n",
    "\n",
    "        cov_x = (x.T @ x) / (N - 1)\n",
    "        cov_y = (y.T @ y) / (N - 1)\n",
    "        cov_loss = self.off_diagonal(cov_x).pow_(2).sum().div(D) + self.off_diagonal(cov_y).pow_(2).sum().div(D)\n",
    "        return repr_loss,cov_loss,std_loss\n",
    "\n",
    "\n",
    "    def off_diagonal(self,x):\n",
    "        n, m = x.shape\n",
    "        assert n == m\n",
    "        return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f08fe8",
   "metadata": {},
   "source": [
    "Now a bunch of generic models that we will use for our setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70ec92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_MLP(torch.nn.Module):\n",
    "    def __init__(self,input_size,out_channels=1,act_out=False,nhidden=50,batchnorm=True):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, nhidden, bias=False),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden, nhidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden, nhidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden, out_channels)\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "        #extra layer for vicreg\n",
    "        self.vicreg = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        self.runbatchnorm = batchnorm\n",
    "        self.batchnorm    = torch.nn.BatchNorm1d(out_channels)\n",
    "        self.output  = torch.nn.Sigmoid()\n",
    "        self.act_out = act_out \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)        \n",
    "        if self.runbatchnorm:\n",
    "            x = self.batchnorm(x)\n",
    "        if self.act_out:\n",
    "            x = self.output(x)\n",
    "        return x\n",
    "\n",
    "    def forward_vicreg(self, x):\n",
    "        out = self.forward(x) \n",
    "        out = self.vicreg(out) #Vicreg adds a layer for training\n",
    "        return out\n",
    "\n",
    "class simple_MLP_onelayer(torch.nn.Module):\n",
    "    def __init__(self,input_size,out_channels=1,act_out=False,nhidden=64,batchnorm=False):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, nhidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden, out_channels),\n",
    "        )\n",
    "        self.output  = torch.nn.Sigmoid()\n",
    "        self.act_out = act_out \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)        \n",
    "        if self.act_out:\n",
    "            x = self.output(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312358b7",
   "metadata": {},
   "source": [
    "Now lets do a simple particle-net model, aka a DGCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cbb62e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "class simple_Edge(torch.nn.Module):\n",
    "    def __init__(self,input_size,out_channels=1,act_out=False,nhidden=64,batchnorm=False):#512\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_feat = input_size\n",
    "        self.part_encode = nn.Sequential(\n",
    "            nn.Linear(input_size, nhidden, bias=False),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(nhidden, nhidden),\n",
    "            nn.ELU(),\n",
    "            nn.Linear(nhidden, nhidden),\n",
    "            #nn.ELU(),\n",
    "            #nn.Linear(nhidden, nhidden),\n",
    "            #nn.ELU()\n",
    "            #nn.Linear(nhidden, out_channels)\n",
    "            #nn.Sigmoid()\n",
    "        )\n",
    "        #self.part_encode.cuda()\n",
    "        self.conv = DynamicEdgeConv(nn=nn.Sequential(nn.Linear(2*nhidden, nhidden), nn.ELU()),k=12, aggr = 'add')\n",
    "        #self.conv.cuda()\n",
    "        self.output = nn.Sequential(\n",
    "            nn.Linear(nhidden, nhidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden, nhidden//2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(nhidden//2, out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels),\n",
    "        )\n",
    "        self.vicreg = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(out_channels, out_channels)\n",
    "        )\n",
    "        #self.output.cuda()\n",
    "        #self.vicreg.cuda()\n",
    "        self.runbatchnorm = batchnorm\n",
    "        self.batchnorm    = torch.nn.BatchNorm1d(out_channels)\n",
    "        self.output_act  = torch.nn.Sigmoid()\n",
    "        self.act_out = act_out \n",
    "\n",
    "    def forward(self, x):\n",
    "        #parts=(x.shape[1])//self.input_feat\n",
    "        #print(x.shape,parts)\n",
    "        parts=x.shape[1]\n",
    "        x_batch = torch.arange(0,x.shape[0])\n",
    "        x_batch = x_batch.repeat_interleave(parts)\n",
    "        #x_batch = x_batch.cuda()\n",
    "        x_part     = x.reshape((parts*x.shape[0],self.input_feat))\n",
    "        x_part_enc = self.part_encode(x_part)\n",
    "        #feats1     = self.conv(x=x_part_enc)#, batch=batch_part)\n",
    "        feats1     = self.conv(x=(x_part_enc,x_part_enc), batch=(x_batch,x_batch))\n",
    "        batch      = x_batch\n",
    "        out, batch = avg_pool_x(batch, feats1, batch)\n",
    "        out = self.output(out)\n",
    "        if self.runbatchnorm:\n",
    "            out = self.batchnorm(out)\n",
    "        if self.act_out:\n",
    "            out = self.output_act(out)\n",
    "        return out\n",
    "\n",
    "    def forward_vicreg(self, x):\n",
    "        out = self.forward(x)\n",
    "        out = self.vicreg(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a5e119",
   "metadata": {},
   "source": [
    "Now we are going to make a contrastive object that does both a contrastive training (model1) and supervised on the space (model2) and a base training (model2_base). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b26edaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class contr_model():\n",
    "    def __init__(self,dataset,inspace=2,batch_size=250,n_epochs=3,n_epochs_mse=3):\n",
    "        super().__init__()\n",
    "        #self.model1      = simple_MLP(data.samples.shape[1],inspace)\n",
    "        #self.model2_base = simple_MLP(data.samples.shape[1],out_channels=1,act_out=True,batchnorm=True)\n",
    "        #self.model2      = simple_MLP_onelayer(inspace,out_channels=1,act_out=True,batchnorm=True)\n",
    "        self.model1      = simple_Edge(data.samples.shape[2],inspace,act_out=False)\n",
    "        self.model2      = simple_MLP(inspace,out_channels=1,act_out=True,batchnorm=True)\n",
    "        self.model2_base = simple_Edge(data.samples.shape[2],out_channels=1,act_out=True,batchnorm=True)\n",
    "        outspace = inspace\n",
    "        #self.model1.cuda(); self.model2.cuda(); self.model2_base.cuda()\n",
    "        self.ctr_loss   = VICRegLoss(lambda_param=1.0,mu_param=1.0,nu_param=1.0)\n",
    "        #self.ctr_loss   = SimCLRLoss(batch_size=batch_size)\n",
    "        #self.mse_loss   = nn.MSELoss()\n",
    "        self.mse_loss   = nn.BCELoss()\n",
    "        self.batch_size = batch_size\n",
    "        self.n_epochs     = n_epochs\n",
    "        self.n_epochs_mse = n_epochs_mse\n",
    "        self.opt1       = torch.optim.Adam(self.model1.parameters(),lr=0.005)\n",
    "        self.opt2       = torch.optim.Adam(self.model2.parameters(),lr=0.00005)\n",
    "        self.opt_base   = torch.optim.Adam(self.model2_base.parameters(),lr=0.005)\n",
    "        self.dataset    = dataset\n",
    "        self.train,self.test = self.split(dataset,0.8)\n",
    "    \n",
    "    def split(self,iDataset,iFrac):\n",
    "        randind         = torch.randperm(len(iDataset)//2)\n",
    "        randtrain       = randind[                      0:int(iFrac*len(randind))]\n",
    "        randtest        = randind[int(iFrac*len(randind)):          len(randind)]\n",
    "        randtrain       = torch.cat((randtrain,(randtrain+len(randind))))\n",
    "        randtest        = torch.cat((randtest ,(randtest +len(randind))))\n",
    "        train           = Subset(iDataset,randtrain)\n",
    "        test            = Subset(iDataset,randtest)\n",
    "        return train,test\n",
    "\n",
    "    def save(self,header=''):\n",
    "        torch.save(self.model1.state_dict(),header+'_encodor.pt')\n",
    "        torch.save(self.model2.state_dict(),header+'_decoder.pt')\n",
    "        torch.save(self.model2_base.state_dict(),header+'_base.pt')\n",
    "\n",
    "    def load(self,header=''):\n",
    "        self.model1.load_state_dict(torch.load(header+'_encodor.pt'))\n",
    "        self.model2.load_state_dict(torch.load(header+'_decoder.pt'))\n",
    "        self.model2_base.load_state_dict(torch.load(header+'_base.pt'))\n",
    "            \n",
    "    def forward(self, x):\n",
    "        x = self.model1(x)        \n",
    "        return x\n",
    "        \n",
    "    def training_loss(self, x1, x2):\n",
    "        x1_hat = self.model1.forward_vicreg(x1)\n",
    "        x2_hat = self.model1.forward_vicreg(x2)\n",
    "        loss_clr,loss_corr,loss_var = self.ctr_loss(x1_hat,x2_hat)\n",
    "        return loss_clr+loss_corr+loss_var\n",
    "    \n",
    "    def training_clr_epoch(self):\n",
    "        running_loss = 0.0; running_loss_clr = 0.0;\n",
    "        train_loader1 = self.train_dataloader()\n",
    "        x1=None; \n",
    "        updates=1\n",
    "        for batch_idx, (x, _)  in enumerate(train_loader1):\n",
    "            #x=x.to('cuda');\n",
    "            self.opt1.zero_grad()\n",
    "            x2 = x[0]\n",
    "            #x2 = torch.reshape(x,((x.shape[1],x.shape[2])))\n",
    "            if (batch_idx+1) % 2 == 0:\n",
    "                if len(x1) == len(x2):\n",
    "                    loss = self.training_loss(x1,x2)\n",
    "                    loss.backward()\n",
    "                    self.opt1.step()\n",
    "                    running_loss += loss\n",
    "                updates = updates + 1\n",
    "            else:\n",
    "                x1=x2.clone().detach()\n",
    "            del x\n",
    "        return running_loss/updates\n",
    "\n",
    "    def validate_clr_epoch(self):\n",
    "        running_loss = 0.0\n",
    "        val_loader1 = self.val_dataloader()\n",
    "        x1=None\n",
    "        updates=1\n",
    "        batch_idx=0\n",
    "        for batch_idx,(x, _ )  in enumerate(val_loader1):\n",
    "            #x=x.to('cuda');\n",
    "            #self.opt1.zero_grad()\n",
    "            x2 = x[0]\n",
    "            #x2 = torch.reshape(x,((x.shape[1],x.shape[2])))\n",
    "            if (batch_idx + 1) % 2 == 0:\n",
    "                if len(x1) == len(x2):\n",
    "                    with torch.no_grad():\n",
    "                        loss = self.training_loss(x1,x2)\n",
    "                        running_loss += loss \n",
    "                updates = updates + 1\n",
    "            else:\n",
    "                x1=x2.clone().detach()\n",
    "            del x\n",
    "        return running_loss/updates\n",
    "\n",
    "    def training_mse_epoch(self,imodel,iloader, iopt):\n",
    "        running_loss = 0.0\n",
    "        train_loader = iloader\n",
    "        updates=0\n",
    "        for batch_idx, (x, y) in enumerate(train_loader):\n",
    "            iopt.zero_grad()\n",
    "            #x     = x.cuda(); y = y.cuda()\n",
    "            x_out = imodel(x)\n",
    "            loss  = self.mse_loss(x_out.flatten(), y.flatten())\n",
    "            loss.backward()\n",
    "            iopt.step()\n",
    "            running_loss += loss \n",
    "            updates = updates+1\n",
    "        return running_loss/updates\n",
    "\n",
    "    def validate_mse_epoch(self,imodel,iloader):\n",
    "        running_loss = 0.0\n",
    "        val_loader   = iloader\n",
    "        updates=0\n",
    "        for batch_idx, (x, y)   in enumerate(val_loader):\n",
    "            #x     = x.cuda(); y = y.cuda()\n",
    "            with torch.no_grad():\n",
    "                x_out = imodel(x)\n",
    "                #print(x_out.shape,y.shape)\n",
    "                loss  = self.mse_loss(x_out.flatten(), y.flatten())\n",
    "                running_loss += loss \n",
    "            updates = updates+1\n",
    "        return running_loss/updates\n",
    "\n",
    "    def test_all(self):\n",
    "        test_loader   = self.test_dataloader()\n",
    "        scores_out    = np.array([])\n",
    "        labels_out    = np.array([])\n",
    "        space_out     = np.array([])\n",
    "        for batch_idx, (x, y)   in enumerate(test_loader):\n",
    "            #x = torch.reshape(x,((x.shape[1],x.shape[2])))\n",
    "            #x = x.to('cuda') \n",
    "            x1_out = self.model1(x) \n",
    "            #x1_out     = x1_out[:,np.r_[self.coords]] ## => projecting out dimensions\n",
    "            x2_out = self.model2(x1_out) \n",
    "            scores_out = np.append(scores_out,x2_out.cpu().detach().numpy())\n",
    "            labels_out = np.append(labels_out,y)\n",
    "            space_out  = np.append(space_out,x1_out.cpu().detach().numpy())\n",
    "        return scores_out,labels_out,space_out\n",
    "    \n",
    "    def test_base(self):\n",
    "        test_loader   = self.test_dataloader()\n",
    "        scores_out = np.array([])\n",
    "        labels_out = np.array([])\n",
    "        space_out  = np.array([])\n",
    "        for batch_idx, (x, y)   in enumerate(test_loader):\n",
    "            #x = x.to('cuda') \n",
    "            x_out = self.model2_base(x) \n",
    "            scores_out = np.append(scores_out,x_out.cpu().detach().numpy())\n",
    "            labels_out = np.append(labels_out,y)\n",
    "            space_out  = np.append(space_out,x_out.cpu().detach().numpy())\n",
    "        return scores_out,labels_out,space_out\n",
    "    \n",
    "    def training_clr(self):\n",
    "        print(\"Training\")\n",
    "        for epoch in range(self.n_epochs):\n",
    "            self.model1.train(True)\n",
    "            loss_train= self.training_clr_epoch()\n",
    "            self.model1.train(False)\n",
    "            loss_valid = self.validate_clr_epoch()\n",
    "            print('Epoch: {} LOSS train: {:.4f} valid: {:.4f}'.format(epoch,loss_train,loss_valid))\n",
    "            self.save()\n",
    "    \n",
    "    def training_mse(self):\n",
    "        for epoch in range(self.n_epochs_mse):\n",
    "            self.model2.train(True)\n",
    "            loss_train = self.training_mse_epoch(self.model2,self.train_dataloader_mse(),self.opt2)\n",
    "            self.model2.train(False)\n",
    "            loss_valid = self.validate_mse_epoch(self.model2,self.val_dataloader_mse())\n",
    "            print('Epoch: {} LOSS train: {} valid: {}'.format(epoch,loss_train,loss_valid))\n",
    "\n",
    "    def training_base_mse(self):\n",
    "        for epoch in range(self.n_epochs_mse):\n",
    "            self.model2_base.train(True)\n",
    "            loss_train = self.training_mse_epoch(self.model2_base,self.train_dataloader_base_mse(),self.opt_base)\n",
    "            self.model2_base.train(False)\n",
    "            loss_valid = self.validate_mse_epoch(self.model2_base,self.val_dataloader_base_mse())\n",
    "            print('Epoch: {} LOSS train: {} valid: {}'.format(epoch,loss_train,loss_valid))\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.ttrain,self.tval  = self.split(self.train,0.8)\n",
    "\n",
    "    def setup_mse(self,stage=None):\n",
    "        train_loader = self.fulltrain_dataloader()\n",
    "        with torch.no_grad():\n",
    "            train_mse_out   = np.array([])\n",
    "            train_label_out = np.array([])\n",
    "            for batch_idx, (x, y)   in enumerate(train_loader):\n",
    "                #x = x.cuda()\n",
    "                #x = torch.reshape(x,((x.shape[1],x.shape[2])))\n",
    "                train_mse_out_tmp = self.model1(x)\n",
    "                train_mse_out   = np.append(train_mse_out,train_mse_out_tmp.cpu().numpy().astype('float32'))\n",
    "                train_label_out = np.append(train_label_out,y)\n",
    "            train_mse_out     = np.reshape(train_mse_out,(len(train_label_out),int(len(train_mse_out)/len(train_label_out))))\n",
    "            #train_mse_out     = train_mse_out[:,np.r_[self.coords]]       \n",
    "            train_label_out   = np.reshape(train_label_out,(len(train_label_out),1))\n",
    "            #randind           = torch.randperm(len(train_mse_out))\n",
    "            train_mse_out     = train_mse_out.astype('float32')\n",
    "            train_label_out   = train_label_out.astype('float32')\n",
    "            train_mse         = DataSet(samples=train_mse_out,labels=train_label_out)\n",
    "            ntot              = len(train_mse)\n",
    "            self.data_train_mse, self.val_train_mse = random_split(train_mse, [int(0.8*ntot),ntot-int(0.8*ntot)])\n",
    "\n",
    "    def fulltrain_dataloader(self):\n",
    "        return DataLoader(self.train, batch_size=self.batch_size,pin_memory=True)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.ttrain, batch_size=1,sampler=BatchSampler(DelphesSampler(self.ttrain,batch_size=self.batch_size),batch_size=2*self.batch_size,drop_last=False),pin_memory=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(self.tval, batch_size=1,sampler=BatchSampler(DelphesSampler(self.tval,batch_size=self.batch_size),batch_size=2*self.batch_size,drop_last=False),pin_memory=True)\n",
    "\n",
    "    def train_dataloader_mse(self):\n",
    "        return DataLoader(self.data_train_mse, batch_size=self.batch_size,shuffle=True,pin_memory=True)\n",
    "\n",
    "    def train_dataloader_base_mse(self):\n",
    "        return DataLoader(self.ttrain, batch_size=self.batch_size,shuffle=True)\n",
    "\n",
    "    def val_dataloader_mse(self):\n",
    "        return DataLoader(self.val_train_mse, batch_size=self.batch_size,shuffle=True,pin_memory=True)\n",
    "\n",
    "    def val_dataloader_base_mse(self):\n",
    "        return DataLoader(self.tval, batch_size=self.batch_size,shuffle=True)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(self.test, batch_size=self.batch_size,shuffle=True,pin_memory=True)\n",
    "\n",
    "    def run_all(self):\n",
    "        self.setup()\n",
    "        self.training_clr()\n",
    "        #torch.cuda.empty_cache()\n",
    "        self.setup_mse()\n",
    "        self.training_mse()\n",
    "        scores_out,labels_out,space_out = self.test_all()\n",
    "        #mask = (mass_out > -70) & (mass_out < 900)\n",
    "        auc = roc_auc_score(y_score=scores_out, y_true=labels_out)\n",
    "        print(\"AUC\",auc)\n",
    "        return scores_out,labels_out,space_out\n",
    "\n",
    "    def run_base(self):\n",
    "        self.setup()\n",
    "        #self.setup_mse()\n",
    "        self.training_base_mse()\n",
    "        scores_out,labels_out,space_out = self.test_base()\n",
    "        #mask = (mass_out > -70) & (mass_out < 900)\n",
    "        auc = roc_auc_score(y_score=scores_out, y_true=labels_out)\n",
    "        print(\"AUC\",auc)\n",
    "        return scores_out,labels_out,space_out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab6f01a",
   "metadata": {},
   "source": [
    "Now lets run everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e0addbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 LOSS train: 0.6931807398796082 valid: 1.0855096578598022\n",
      "Epoch: 1 LOSS train: 0.6932010054588318 valid: 1.4712456464767456\n",
      "Epoch: 2 LOSS train: 0.6931895613670349 valid: 1.4250532388687134\n",
      "AUC 0.5\n"
     ]
    }
   ],
   "source": [
    "#print(data.samples.shape)\n",
    "ctr_model=contr_model(data,inspace=8)#8 dimensional Contrastive Space\n",
    "scores_base,labels_base,space_base=ctr_model.run_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2d3605ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Epoch: 0 LOSS train: 4.2012 valid: 2.5611\n",
      "Epoch: 1 LOSS train: 1.8330 valid: 1.4599\n",
      "Epoch: 2 LOSS train: 1.2969 valid: 1.1756\n",
      "Epoch: 0 LOSS train: 0.71220463514328 valid: 0.6963523030281067\n",
      "Epoch: 1 LOSS train: 0.685274064540863 valid: 0.6841124296188354\n",
      "Epoch: 2 LOSS train: 0.6806195974349976 valid: 0.6812255382537842\n",
      "AUC 0.582115945\n"
     ]
    }
   ],
   "source": [
    "scores_ctr,labels_ctr,space_ctr=ctr_model.run_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c54c6136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def rocplot(iV,iLabel):\n",
    "    auc_value                  = roc_auc_score(y_score=iV, y_true=iLabel)\n",
    "    fpr_value, tpr_value, cuts = roc_curve    (y_score=iV, y_true=iLabel)\n",
    "    if auc_value < 0.5:\n",
    "        auc_value                  = roc_auc_score(y_score=iV, y_true=(1-iLabel))\n",
    "        fpr_value, tpr_value, cuts = roc_curve    (y_score=iV, y_true=(1-iLabel))\n",
    "    return fpr_value,tpr_value,auc_value\n",
    "\n",
    "def plotROCs(scores_out0,labels_out0,scores_out1,labels_out1):\n",
    "    figure, axis = plt.subplots(1, 1,figsize=(10,5))\n",
    "    fprt,tprt,auct=rocplot(scores_out0,labels_out0)\n",
    "    fpr1,tpr1,auc1=rocplot(scores_out1,labels_out1)\n",
    "    #fpr2,tpr2,auc2=rocplot(scores_out2,labels_out)\n",
    "    axis.plot(fprt, tprt,label=\"diff:{:.6f}\".format(auct))\n",
    "    axis.plot(fpr1, tpr1,label=\"sig:{:.6f}\".format(auc1))\n",
    "    #axis.plot(fpr2, tpr2,label=\"bkg:{:.6f}\".format(auc2))\n",
    "    axis.set_xscale('log')\n",
    "    axis.set_xlabel(\"fpr\")\n",
    "    axis.set_ylabel(\"tpr\")\n",
    "    axis.legend(title=\"auc\")\n",
    "    plt.show()\n",
    "    \n",
    "plotROCs(scores_base,labels_base,scores_ctr,labels_ctr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92aa4e26",
   "metadata": {},
   "source": [
    "Now lets plot the contrastive space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9e36dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 8)\n"
     ]
    }
   ],
   "source": [
    "import corner\n",
    "\n",
    "space_ctr=np.reshape(space_ctr,(space_ctr.shape[0]//8,8))\n",
    "print(space_ctr.shape)\n",
    "arrs=[r\"$x$\",r\"$y$\"]\n",
    "figure = corner.corner(space_ctr[labels_ctr==0],quantiles=[0.16, 0.5, 0.84],show_titles=True,title_kwargs={\"fontsize\": 12},color='green')\n",
    "corner.corner(space_ctr[labels_ctr==1], fig=figure,color='orange')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3988fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
